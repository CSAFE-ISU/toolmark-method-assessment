% !TeX program = pdfLaTeX
\documentclass[12pt]{article}
\usepackage{amsmath}
\usepackage{amsthm}
\usepackage{graphicx,psfrag,epsf}
\usepackage{enumerate}
\usepackage{natbib}
\usepackage{booktabs}
\usepackage{longtable}
\usepackage{array}
\usepackage{multirow}
\usepackage{subfig}
\usepackage[table]{xcolor}
\usepackage{wrapfig}
\usepackage{float}
\usepackage{colortbl}
\usepackage{hyperref}
\usepackage{pdflscape}
\usepackage{tabu}
\usepackage{threeparttable}

\usepackage{url} % not crucial - just used below for the URL

%\pdfminorversion=4
% NOTE: To produce blinded version, replace "0" with "1" below.
\newcommand{\blind}{0}

% DON'T change margins - should be 1 inch all around.
\addtolength{\oddsidemargin}{-.5in}%
\addtolength{\evensidemargin}{-.5in}%
\addtolength{\textwidth}{1in}%
\addtolength{\textheight}{1.3in}%
\addtolength{\topmargin}{-.8in}%

\newenvironment{definition}[1]% environment name 
{% begin code 
  \par\vspace{.75\baselineskip}\noindent 
  \textbf{Definition (#1)}\begin{itshape}% 
  \par\vspace{.5\baselineskip}\noindent\ignorespaces 
}% 
{% end code 
  \end{itshape}\ignorespacesafterend 
}

\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}

\begin{document}

\def\spacingset#1{\renewcommand{\baselinestretch}%
{#1}\small\normalsize} \spacingset{1}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\if0\blind
{
  \title{\bf Adaption of the Chumbley Score to matching of bullet striation marks}

  \author{
        Ganesh Krishnan \thanks{The authors gratefully acknowledge \ldots{}} \\
    Department of Statistics, Iowa State University\\
     and \\     Heike Hofmann \\
    Department of Statistics and CSAFE, Iowa State University\\
      }
  \maketitle
} \fi

\if1\blind
{
  \bigskip
  \bigskip
  \bigskip
  \begin{center}
    {\LARGE\bf Adaption of the Chumbley Score to matching of bullet striation marks}
  \end{center}
  \medskip
} \fi

\bigskip
\begin{abstract}

\end{abstract}

\noindent%
{\it Keywords:} 3 to 6 keywords, that do not appear in the title
\vfill

\newpage
\spacingset{1.45} % DON'T change the spacing!

\newcommand{\hh}[1]{{\textcolor{orange}{#1}}}
\newcommand{\gk}[1]{{\textcolor{green}{#1}}}
\newcommand{\cited}[1]{{\textcolor{red}{#1}}}

\setlength\parindent{0pt}

\tableofcontents
\newpage

\section{Introduction and Background}\label{introduction-and-background}

\subsection{Motivation}\label{motivation}

Same source analyses are a major part of an Forensic Toolmark Examiner's
job. In current practice examiners make these comparisons by visual
inspection under a comparison microscope and come to one of the
following four conclusions: identification, inconclusive, elimination or
unsuitable for examination\textasciitilde{}\citep{afte-toolmarks1998}.
These conclusions are made on the basis of ``unique surface contours''
of the two toolmarks being in ``sufficient agreement''
\citep{afte-toolmarks1998}. AFTE describes the term ``sufficient
agreement'' as the possibility of another tool producing the markings
under comparison, as practically impossible \citep{afte-toolmarks1998}.
Potential subject bias in the assessment as well as the lack of
specified error rates are the main points of criticisms first raised by
the National Research Council in 2009 \citep{NAS:2009} and later
emphasized further by the President's Council of Advisors on Science and
Technology \citep{pcast2016}.

Technological advances, such as profilometers and confocal microscopy
allow to measure 3D surfaces in a high-resolution digitized form. This
technology has become more accessible over the last decade, and has made
its way into topological images of ballistics evidence, such as bullet
lands and breech faces
\citep{DeKinder1, DeKinder2, Bachrach1, vorburger2016}. Digitized images
of 3D surfaces of form the data basis of statistical analysis of
toolmarks. A statistical approach based on data removes both
subjectivity from the assessment and allows a quantification of error
rates for both false positive and false negative identifications.

\hh{In the next page and a half it is easy to lose the red line. It might help to include a table with an overview.
The table should include the reference to the paper, the data used, the statistical method and the associated error rates.}
Various toolmarks have been studied in the literature:
\citet{manytoolmarks1} and \citet{chumbley} have been analyzing
screwdriver marks digitized using a profilometer; \citet{manytoolmarks2}
have investigated 3D marks from screwdriver, tongue and groove pliers
captured using a confocal microscope; \citet{afte-chumbley} have been
investigated digitized marks from slip-joint pliers generated by a
surface profilometer.

\hh{We need an additional sentence here to get from the data to the statistical methods ... }
\citet{manytoolmarks2} define a relative distance metric and use it as
similarity measure between two toolmarks. \citet{manytoolmarks1} extract
many small segments in the markings of two toolmarks and compare
similiarity using a maximum pearson correlation coefficient. The
Chumbley scoring method, first introduced by \citet{chumbley}, uses a
similar but more extensive framework based on a Mann-Whitney U test of
the resulting correlation coefficients. This approach is
non-deterministic, because segments are chosen randomly. \citep{hadler}
make the score deterministic for each pair of toolmarks by choosing
segments for comparison systematically. This approach also ensures
independence between segements of striae. In this paper, we are
investigating the applicability of the Chumbley scoring method by
\citet{hadler} to assess striation marks on bullet lands for same-source
identification.

Striation marks on bullets are made by impurities in the barrel. As the
bullet travels through the barrel, these imperfections leave
``scratches'' on the bullet surface. Typically, only striation marks in
the land engraved areas (LEAs) are considered \citet{afte-article1992}.
Bullet lands are depressed areas between the grooves made by the rifling
action of the barrel. Compared to toolmarks made by screwdrivers
striation marks on bullets are typically much smaller, both in length
and in width. Bullets also have a curved cross-sectional topography.
Figure \ref{fig:rgl} shows us how the signature from a bullet land
(bottom) lines up with the image of the land (top) from which it was
extracted. We can also see in the figure how the depth and relative
position of the striation markings seen in the image are interpreted as
the signature.

Bullet matching methods are usually based on these associated
signatures. \citet{chu2013} use an automatic method for counting
consecutive matching striae (CMS). The authors report an error rate of
52\% of the known same source lands comparisons as misidentified (false
negative) and zero false positives for known different source lands.
\citet{ma2004} and \citet{vorburger2011} discuss CCF (cross-correlation
function) and its discriminating power and applicability for same-source
analyses of bullets, but do not provide any error rates in their
discussion. \citet{aoas} use multiple features like CCF, CMS, D
(distance measure) etc in a random forest based method and compare every
land against every other land of digitised versions of Hamby 252 and
Hamby 44 \citep{hamby} published on the NIST Ballistics Database
\citep{nist}. The authors report an out-of-bag overall error rate of
0.46\%, comprised of an error rate of 30.05\% of same-source pairs that
were not identified and an error rate of 0.026\% of different-source
pairs that were incorrectly identified as same-source.

The Chumbley score provides us with another approach in the same-source
assessment of bullet striation marks. \citet{chumbley} compare two
toolmarks for same-source. The data for this study was obtained from 50
sequentially manufactured screwdriver tips. \citet{chumbley} report
error rates for markings made by the tips at different angles. For
markings made at 30 degree the authors report an average false negative
error rate of 0.089 and an average false positive error rate of 0.023.
For other angles of 60 and 85 degrees the false negatives error rate is
0.09 while the rate of false positives decreases to 0.01. The paper by
\citet{hadler} is based on the same data but the authors focus on
markings made under the same angle. The error rates associated with the
deterministic version of the score are 0.06 for false negatives and a
false positive error rate of 0.

\begin{figure}
\centering
\includegraphics[width=\textwidth]{images/B6-B2-L6-rescaled.png}


\caption{\label{fig:rgl} Image of a bullet land from a confocal light microscope at 20 fold magnification (top) and a chart of the corresponding signature of the same land (bottom). The dotted lines connect some peaks visible in both visualizations.}

\end{figure}

\subsection{Scans for land engraved
areas}\label{scans-for-land-engraved-areas}

Comparisons of striae from bullets are usually based on comparisons of
striae in land engraved areas, which are extracted in form of cross
sections, called \emph{profiles} \citep{aoas,ma2004}. From profiles
bullet \emph{signatures} \citep{chu2013,aoas} are extracted as residuals
of a loess fit or Gaussian filter. This effectively removes topographic
structure from the data in the attempt to increase the signal to noise
ratio. The span of the loess fit was found using cross-validation, as
described by \citet{aoas}.

\hh{don't split the discussion on the size. between the next paragraph and }
There are two sources of scans for sets from the Hamby study available
to us: scans of Hamby 44 and Hamby 252 are available from the NIST
database \citep{nist}. Hamby 44 has also been made available to us and
has been scanned locally for CSAFE at the Roy J.~Carver High Resolution
Microscopy Facility using a Sensofar confocal light microscope. Scans in
the NIST database are made with a NanoFocus at 20x magnification. The
resolutions of the two instruments are different: the NIST scans are
taken at a resolution of 1.5625 \(\mu m\) per pixel, while the CSAFE
scans are available at a resolution of 0.645 \(\mu m\) per pixel. The
length of an average bullet land from Hamby (9 mm Ruger P85) is about 2
millimeter, resulting in signatures of about 1200 pixels for NIST scans,
and about 3000 pixels for CSAFE scans.

In comparison, scans from the profilometer used by
\citet{chumbley, hadler} were taken at a resolution of about 0.73
\(\mu m\) per pixel. The screw driver toolmarks are about 7 mm in length
\citep{manytoolmarks1}, for a total of over 9000 pixels for the width of
these scans.

This severe limitation in the amount of available data poses the main
challenge in adapting the Chumbley score to matching bullet lands,
because of the resulting loss in power.

\subsection{The Chumbley Score Test}\label{the-chumbley-score-test}

The Chumbley score algorithm takes input in form of two digitized
toolmarks. The toolmark is in form of \(z(t)\) which is a spatial
process for location indexed by \(t\). \(t\) here denotes equally spaced
pixel locations for the striation marks under consideration,
\(t = 1, ..., T\). Let further \(z^s(t)\) denote a vector of markings of
length \(s\) starting in location \(t\).

Let \(x(t_1)\), \(t_1 = 1,2,...T_1\) and \(y(t_2)\), \(t_2 = 1,2...T_2\)
be two digitized toolmarks (where \(T_1\) and \(T_2\) are not
necessarily equal). The toolmarks under consideration are potentially
from two different sources or the same source. \(T_1\) and \(T_2\), as
represented above, are the final pixel indexes of each marking and
therefore give the respective lengths of the markings.

In a pre-processing step the two markings are smoothed using a lowess
\citep{lowess} with coarseness parameter \(c\). Originally, this
smoothing is intended to remove drift and (sub)class characteristics
from individual markings, however, in the setting of matching bullet
striae, we can also make use of this mechanism to separate bullet
curvature in profiles from signatures before matching signatures.

After removing sub-class structure, the Chumbley scores is calculated in
two steps: an optimization step and a validation step. In the
optimization step, the two markings are aligned horizontally such that
within a pre-defined window of length \(w_o\) the correlation between
\(x(t_1)\) and \(y(t_2)\) is maximized: \[
\left(t_1^o, t_2^o\right) = \mathop{\arg \max}\limits_{1 \le t_1 \le T_1, 1 \le t_2 \le T_2} \text{cor} \left(x^{w_o} (t_1), y^{w_o}(t_2) \right)
\] This results in an optimal vertical (in-phase) shift of
\(t_1^o - t_2^o\) for aligning the two markings.
\hh{We will denote the relative optimal locations as $t_1^*$ and $t_2^*$, where $t_i^* = t_i^o/(T_i-w_o)$ for $i=1,2$, such that $t_1^*, t_2^* \in [0,1]$. Once (sub-)class characteristics are removed, the relative optimal locations should be distributed according to a uniform distribution in $[0,1]$. }

In the validation step, two sets of windows of size \(w_v\) are chosen
from both markings (see Figure \ref{fig:win-comparison}). In the first
set, pairs of windows are extracted from the two markings using the
optimal vertical shift as determined in the first step, whereas for the
second set the windows are extracted using a different (out-of-phase)
shift.

More precisely, let us define starting points \(s_i^{(k)}\) for each
signature \(k = 1, 2\) as

\begin{eqnarray}\label{eq.start}
s^{(k)}_i = 
\begin{cases}
t_k^* + i w_v & \text{ for } i < 0 \\
t_k^* + w_ o + i w_v & \text{ for } i \ge 0,
\end{cases}
\end{eqnarray}

for integer values of \(i\) with \(0 < s^{(k)}_i \le T_k - w_v\).

Same-shift pairs of length \(w_v\) are defined in \citet{hadler} as all
pairs \((s_i^{(1)}, s_i^{(2)})\) for all integer values \(i\) for which
both \(s_i^{(1)}\) and \(s_i^{(2)}\) are defined. Similarly,
different-shift pairs are defined as \((s_i^{(1)}, s_{-i-1}^{(2)})\) for
all \(i\) where both \(s_i^{(1)}\) and \(s_{-i-1}^{(2)}\) are defined
(see \autoref{sketch-same-diff}).

\begin{figure}[hbtp]
\centering
\includegraphics[width=.7\textwidth]{images/sketch-same.png}

\includegraphics[width=.7\textwidth]{images/sketch-diff.png}
\caption{\label{sketch-same-diff}Sketch of same-shift pairings  (top) and different-shift pairings (bottom). Filled in rectangles show pairings resulting in correlations, unfilled rectangles are segments without a match.}
\end{figure}

\begin{figure}

{\centering \includegraphics[width=\textwidth]{figures/win-comparison-1} 

}

\caption{Two markings made by the same source. For convenience, the markings are moved into phase on the left and out-of phase on the right. In-phase (left) and out-of-phase (right) samples are shown by the light grey background. The Chumbley-score is based on a Mann-Whitney U test of the correlations derived from these two sets of samples.}\label{fig:win-comparison}
\end{figure}

For both same- and different-shift pairs correlations between the
markings are calculated. The intuition here is that for two markings
from the same source the correlation for the in-phase sample should be
high, while the correlations of the out-of-phase sample provide a
measure for the base-level correlation for non-matching marks of a given
length \(w_v\). The Chumbley score is then computed as a Mann Whitney U
statistic to compare between in-phase sample and out-of-phase sample. In
the original method proposed in \citet{chumbley} both in-phase and
out-of-phase sample are extracted randomly, whereas \citet{hadler}
proposed the above specified deterministic rules for both samples to
make the resulting score deterministic while simultaneously avoiding
overlaps within selected marks to ensure independence.

\subsection{A problem with failures and
modification}\label{a-problem-with-failures-and-modification}

Looking closer at \autoref{eq.start}, we see that by definition, some
number of tests will fail to produce a result, either because the number
of eligible same-shift pairs is zero, or the number of different-shift
opairs is zero.

The number of same-shift pairs will be zero, if the optimal locations
\(t_1^{o}\) and \(t_2^{o}\) are so far apart, that no segments of size
\(w_v\) are left on the same sides of the optimal locations, i.e.
\(t_1^{o} < w_v\) and \(t_2^{o} > T_2-w_o-w_v\) or
\(t_1^{o} < T_1- w_o - w_v\) and \(t_2^{o} < w_v\), i.e.~we have a
failure rate of \[
P\left( t_1^{o} < w_v \ \cap \ t_2^{o} > T_2-w_o-w_v\right) + P\left( t_1^{o} < T_1- w_o - w_v \ \cap \ t_2^{o} < w_v\right).
\] While we can assume that once (sub-)class characteristics are
removed, optimal locations \(t_i^{o}\) are uniformly distributed across
the length of the profile, we cannot assume that \(t_1^o\) and \(t_2^o\)
are independent of each other. In particular, for same-source profiles,
we would expect a strong dependency between these locations, in which
case a large difference between locations is unlikely. However, for
different source matches, we can assume that locations are independent.
In that case, we expect a test to fail with a probability of
\(\frac{2 w_v^2}{(T_1-w_o)(T_2-w_o)}\). For an average length of \(T_i\)
of 1200 pixels, \(w_o = 120\) pixels and \(w_v = 30\) pixels this
probability is about 0.0015.

The number of possible different-shift pairs also depends on the
location of the optimal locations \(t_1^o\) and \(t_2^o\). Whenever the
optimal locations are close to the boundaries, the number of possible
pairings decreases and reaches zero, if \(t_i^{(o)} < w_v\) or
\(t_i^{(o)} > T_i-w_o- w_v\). Assuming a correlation between optimal
locations \(t_1^o\) and \(t_2^o\) of close to one for same-source
profiles, this results in an expected rate of failure of
\(2 w_v / (T_i-w_o)\), or about 5.6\% for an average length of \(T_i\)
of 1200 pixels, \(w_o = 120\) pixels and \(w_v = 30\) pixels. Assuming
independence in the optimal locations for different source profiles the
expected probability for a failed test is, again,
\(\frac{2 w_v^2}{(T_1-w_o)(T_2-w_o)}\).

While failures due to missing correlations from same-shift pairs are
unavoidable by definition of the Chumbley score, failures due to missing
correlations from different-shift pairs can be prevented by using a
different strategy in assigning pairs.

Using the same notation as in \autoref{eq.start}, we define same-shift
pairs identical to \citet{hadler} as pairs \((s_i^{(1)}, s_i^{(2)})\)
for all \(i\) where the boundary conditions of both sequences are met
simultaneously. Let us assume that this results in \(I\) pairs. Define
\(s_{(j)}^{(k)}\) to be the \(j\)th starting location in sequence
\(k = 1, 2\),
i.e.~\(s_{(1)}^{(k)} < s_{(2)}^{(k)} < ... < s_{(I)}^{(k)}\).

We then define the pairs for different-shifts as

\begin{equation}\label{eq.diff2}
\left(s_{(j)}^{(1)}, s_{(I-j+1)}^{(1)} \right) \text{ for } j = 
\begin{cases}
1, ..., I & \text{ for even } I \\
1, ..., (I-1)/2, (I-1)/2 + 2, ..., I & \text{ for odd } I
\end{cases},
\end{equation}

i.e.~for an odd number of same-shift correlations, we skip the middle
pair for the different-shift correlations (see \autoref{sketch-diff-2}).
This pairing ensures that the number of different-shift pairings is the
same or at most one less than the number of same-shift pairings in all
tests.
\hh{In the remainder of the paper, we will refer to the algorithm defined by \citet{hadler} as {\bf (CS1)} and the suggested modified algorithm as {\bf (CS2)} and compare their performance on the available scans of the Hamby study.}

\begin{figure}[hbtp]
\centering
\includegraphics[width=.7\textwidth]{images/sketch-diff-2.png}
\caption{\label{sketch-diff-2}Sketch of adjusted different-shift pairings. At most one of the same-shift pairings can not be matched with a different-shift pair. }
\end{figure}

\section{Testing setup}\label{testing-setup}

\subsection{The Data}\label{the-data}

\begin{figure}

{\centering \includegraphics[width=\textwidth]{figures/sigs-profiles-1} 

}

\caption{Bullet land profile (left) and the corresponding signature (right) for one of the lands of Hamby-44.}\label{fig:sigs-profiles}
\end{figure}

Lands for all Hamby-44 and Hamby-252 scans are made available through
the NIST ballistics database \citep{nist} and are considered, here. Both
of these sets of scans are part of the larger Hamby study \citep{hamby}.
Each set consists of twenty known bullets (two each from ten
consecutively rifled Ruger P85 barrels) and fifteen questioned bullets
(each matching one of the ten barrels). Ground truth for both of these
Hamby sets is known and was used to assess correctness of the tests
results.

Profiles for each bullet land were extracted from scans close to the
heel of the bullet while avoiding break-off as described in
\citet{aoas}.

\subsection{Setup}\label{setup}

Both algorithms (CS1) and (CS2) are implemented in the R package
\texttt{toolmaRk} \citep{toolmark}. We applied both methods to all
pairwise land-to-land comparisons of the Hamby scans provided by NIST
for a total of 85,491 land-to-land comparisons.

\section{Results}\label{results}

\subsection{Failed Tests}\label{failed-tests}

Initially, the default settings suggested in \citet{hadler} were used:
\(w_o = 120\) pixels or about 190 \(\mu m\) (ten percent of the average
length of profiles) and coarseness \(c = 0.25\). \autoref{fig:fails}
shows the percentage of failed tests among the 85,491 land-to-land
comparisons of the NIST data for different values of the validation
window size \(w_v\). For same-source lands up to 12.5 percent of the
tests fail using CS1. The highest percentage of failed tests under CS2
is 1.3\% for different source tests using a validation window size
\(w_v\) of 60 pixels.
\hh{Rates of expected failures are based on simulation runs using covariances between locations of same-source profiles of 0.854, and 0.120 for locations from different-source profiles, matching observed covariances for the Hamby scans. }\hh{ Observed failure rates are higher than expected. This might be due to remaining sub-class structure at a coarseness of 0.3 resulting in a distribution of optimal locations different from the assumed uniform. }

\begin{figure}

{\centering \includegraphics[width=0.7\textwidth]{figures/fails-1} 

}

\caption{Percent of failed land-to-land comparisons using an optimization window $w_o = 120$ and a coarseness of $c = 0.25$. With an increase in the size of the validation window  a higher percentage of tests fails under both methods (CS1) and (CS2), but the percentage of failed tests is much smaller under (CS2). Observed failure rates are higher than expected rates.}\label{fig:fails}
\end{figure}

\subsection{Coarseness}\label{coarseness}

The purpose of the coarseness parameter is to remove (sub-)class
characteristics from profiles before comparisons for matching.
\citet{hadler} suggest a coarseness parameter of 0.25 in the setting of
toolmark comparisons. For bullet lands, coarseness might need to be
adjusted because of the strong effect bullet curvature has on profiles.

\hh{\autoref{fig:profile-sketch} gives an overview of the effect of different coarseness parameters: from left to right, coarseness levels $c$ are varied in steps of 0.05 from 0.1 to 0.3. The top row shows  resulting signature after smoothing the profile shown in Figure~\ref{fig:sigs-profiles} with the coarseness specified. 
The histograms in the bottom row show the relative optimal location $t^*$. Optimal locations are distributed uniformly once (sub-)class characteristics are removed. However, for coarseness values of $c > 0.20$ we see quite distinct boundary effects: optimal locations $t^*$ are found at the very extreme ends of a profile more often than one would expect based on a uniform distribution.}

\begin{figure}

{\centering \includegraphics[width=\textwidth]{figures/profile-sketch-1} 

}

\caption{Overview of the effect of different coarseness parameters $c$ on the profile shown in Figure \ref{fig:sigs-profiles} (top). The bottom row shows histograms of  the (relative) optimal locations $t^o$ identified in the optimization step for different values of the coarseness parameter $c$. }\label{fig:profile-sketch}
\end{figure}

\subsection{Type II error rates}\label{type-ii-error-rates}

\begin{figure}

{\centering \includegraphics[width=0.7\textwidth]{figures/unnamed-chunk-2-1} 

}

\caption{Side-by-side comparison of type II error rates of methods CS1 and CS2 by size of optimization window $w_o$.}\label{fig:unnamed-chunk-2}
\end{figure}

\subsubsection{Results for Signatures}\label{results-for-signatures}

\hh{For signatures from NIST scans we see three problems: 
\begin{enumerate}
\item type-2 error rate is at best 30\% for a type-1 error rate of 5\%, which is well above the error rates we see for tool marks from screw drivers, see figure \ref{fig:type2};
\item the observed type-1 error, which generally close to the nominal type-1 error rate, depends on the size of the optimization window: as the window size increases, the observed type-1 error decreases, see figure \ref{fig:type1};
\item the Chumbley-score fails to provide a result for up to 3\% of the cases. The number of failed tests increases linearly in the size used for the window in the optimization step. The rate of failed tests is considerably higher when the two lands are from same source than when the lands are from different sources, see figure \ref{fig:missings}. 
\end{enumerate}
}

Figure \ref{fig:missings} gives an overview of the number of failed
tests, i.e.~tests in which a particular parameter setting did not return
a valid result. This happens e.g.~when the shift to align two markings
is so large, that the remaining overlap is too small to accommodate
windows for validation. The problem is therefore exacerbated by a larger
validation window. Figure \ref{fig:missings}(left) also shows that the
number of failed tests is approximately linear in the size of the
optimization window. Tests also fail at a higher rate than expected when
the markings are from the same source (right). This difference is the
least pronounced around an optimized window size \(w_o\) of around 120.
However, even in this scenario, the number of failed tests for markings
from the same source is about twice as high as expected given the number
of same source and different source pairings in the data set.

\begin{figure}

{\centering \includegraphics[width=.8\textwidth]{figures/type2-1} 

}

\caption{Type II error rates observed across a range of window sizes for optimization $w_o$. For a window size of $w_o = 120$ we see a drop in type II error rate across all type I rates considered. Smaller validation sizes $w_v$ are typically associated with a smaller type II error.}\label{fig:type2}
\end{figure}

\begin{figure}

{\centering \includegraphics[width=\textwidth]{figures/type1-1} 

}

\caption{Comparison of observed and nominal type I error rates  across a range of window sizes for optimization $wo$. The horizontal line in each facet indicates the nominal type I error rate.}\label{fig:type1}
\end{figure}

\begin{figure}

{\centering \includegraphics[width=\textwidth]{figures/missings-1} 

}

\caption{The number of failed tests increases with an increase in the size of the optimization window (left). Unfortunately there is also a dependency between failed tests and ground truth. The plot on the right shows the ratio of the number of land pairs from same sources and different sources for failed tests. For small optimization windows and large windows the number of failed tests for same-source land-to-land comparisons is increasing. Even in the minimum, same-source land-to-land comparisons fail at twice the rate that they are expected to based on the ratio of the number of known matches and known non-matches (horizontal line).}\label{fig:missings}
\end{figure}

\begin{table}[ht]
\caption{\label{tab:type2} Type II error rates for profiles and signatures of bullet lands. For profiles, a coarseness value of $c = 0.25$ is used to remove bullet curvature.}
\centering
\begin{tabular}{rlrrrr}
  \hline
validation && \multicolumn{4}{l}{Nominal type I error rate $\alpha$}\\  
window $w_v$ & source & 0.001 & 0.005 & 0.01 & 0.05 \\ 
  \hline
 30 & profiles & 54.40 & 43.80 & 39.70 & 30.00 \\ 
   30 & signatures & 55.00 & 45.40 & 41.40 & 31.10 \\ \hline
   50 & profiles & 58.50 & 44.40 & 40.70 & 28.70 \\ 
   50 & signatures & 62.60 & 49.60 & 44.20 & 30.50 \\ 
   \hline
\end{tabular}
\end{table}

\section{Conclusion}\label{conclusion}

The results suggest that the Nominal type I error \(\alpha\) value shows
dependence on the size of the window of optimization. For a given window
of optimization the actual Type I error is comparable to the nominal
level for only a select few validation window sizes and for comparable
validation window sizes of 30 and 50 as done here, the actual type I
error does not seem to vary as much as it varies with the optimization
window sizes . A Test Fail, i.e.~tests in which a particular parameter
setting did not return a valid result, happens, when the shift to align
two signatures is so large, that the remaining overlap is too small to
accommodate windows for validation, depends on whether known-match or
known non-matches has predictive value, with test results from different
sources having a much higher chance to fail. On conducting an analysis
of all known bullet lands using the adjusted chumbley algorithm, Type II
error was identified to be least bad for window of validation 30 and
window of optimization 120. In case of unsmoothed raw marks (profiles),
Type II error increases with the amount of smoothing and least for
LOWESS smoothing coarseness value about 0.25 or 0.3. In an effort to
identify the level of adaptiveness of the algorithm, comparisons were
made between signatures and profiles. Their comparison with respect to
validation window size for a fixed optimization window size suggested
that, profiles have a total error (i.e all incorrect classification of
known-matches and known non-matches) greater than or equal to the total
error of signatures for all sizes of validation window. Profiles also
fail more number of times than signatures in a test fail (for different
coarseness keeping windows fixed and also for different validation
windows keeping coarseness fixed) which lets us conclude that the
behaviour of the algorithm for the profiles instead of pre-processed
signatures is not better. Finally it should be noted that the current
version of the adjusted chumbley algorithm seems to fall short when
compared to other machine-learning based methods \citet{aoas}, and some
level of modification to the deterministic algorithm needs to be
identified and tested that would reduce the number of incorrect
classifications.

\bibliographystyle{agsm}
\bibliography{bibliography}

\end{document}
